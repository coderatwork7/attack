# attack
    Attack influence: An attack can have a causative influence if it aims to introduce vulnerabilities to be exploited at the classification phase by manipulating training data, or an exploratory influence if the attack aims to find and subsequently exploit vulnerabilities at classification phase. The attacker's capabilities might also be influenced by the presence of data manipulation constraints.[26]
    Security violation: An attack can cause an integrity violation if it aims to get malicious samples misclassified as legitimate, or it may cause an availability violation if the goal is to increase the wrong classification rate of legitimate samples, making the classifier unusable (e.g., a denial of service).
    Attack specificity: An attack can be targeted if specific samples are considered (e.g. the adversary aims to allow a specific intrusion or wants a given spam email to get past the filter), or indiscriminate.


Attacks against clustering algorithms
Clustering algorithms have been increasingly adopted in security applications to find dangerous or illicit activities. For instance, clustering of malware and computer viruses aims to identify and categorize different existing malware families, and to generate specific signatures for their detection by anti-viruses or signature-based intrusion detection systems like Snort. 

    AdversariaLib - includes implementation of evasion attacks
    AdLib - Python library with a scikit-style interface which includes implementations of a number of published evasion attacks and defenses
    AlfaSVMLib - Adversarial Label Flip Attacks against Support Vector Machines[37]
    Poisoning Attacks against Support Vector Machines, and Attacks against Clustering Algorithms
    deep-pwning - Metasploit for deep learning which currently has attacks on deep neural networks using Tensorflow.[38] This framework currently updates to maintain compatibility with the latest versions of Python.
    Cleverhans - A Tensorflow Library to test existing deep learning models versus known attacks
    foolbox - Python Library to create adversarial examples, implements multiple attacks
    SecML - Python Library for secure and explainable machine learning - includes implementation of a wide range of ML and attack algorithms, support for dense and sparse data, multiprocessing, visualization tools.
